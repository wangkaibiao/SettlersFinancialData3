<!DOCTYPE html>
<html>
<head>

    <!-- Load TensorFlow.js -->
    <script src="tf.min.js"></script>
    <!-- Load Posenet -->
    <script src="posenetPC.min.js"></script>
    <meta charset="utf-8">
    <title>web RTC posenet</title>

</head>


<body>
    <div>
        <!--
        <video id="mp4" width="300" style="margin-top:15px;" autoplay="true">
        <source src="videomp4.mp4" type="video/mp4" />
        -->
        <video id="mp4"></video>
    </div>

    <div class="booth">
        <video id="video" width="130" height="130"></video>
        <canvas id='canvas' width='130' height='130'></canvas>
        <!--
        <img id='cat' src='' >
        <img id='cat' src='' crossorigin="anonymous">
        也可以-->
    </div>

    <div class="buttons">
        <button id='tack'> snap shot</button>
        <button id='loadmodel'>loadmodel</button>
        <button id='play'>play</button>
    </div>

    <div class="footer-text">
        <p id="singlePose">结果显示</p>
    </div>
 
    <script>
    function isAndroid() {
        return /Android/i.test(navigator.userAgent);    }

    function isiOS() {
        return /iPhone|iPad|iPod/i.test(navigator.userAgent);    }

    function isMobile() {
        return isAndroid() || isiOS();    }

    const videoWidth = 130;
    const videoHeight = 130;
    const color = 'aqua';

    async function setupCamera() {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            alert('Browser API navigator.mediaDevices.getUserMedia not available');    }
        const video = document.getElementById('video');
        const mobile = isMobile();
        try{
            const stream = await navigator.mediaDevices.getUserMedia({
                'audio': false,
                'video': {
                    facingMode: 'user',
                    width: mobile ? undefined : videoWidth,
                    height: mobile ? undefined : videoHeight,}    ,    }    );
            video.srcObject = stream;
           }catch(err){alert(err)}
        return new Promise((resolve) => {
            video.onloadedmetadata = () => {
                resolve(video);    };    }    );    }

    async function loadVideo() {
        const video = await setupCamera();
	    video.play();
	    const net = await posenet.load(0.75);
	    detectPoseInRealTime(video, net);    }

	function detectPoseInRealTime(video, net) {
	    const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        // since images are being fed from a webcam
        const flipHorizontal = true;

        canvas.width = videoWidth;
        canvas.height = videoHeight;
	    //document.getElementById("output").style.display = "inline";
        //L = videoWidth / 5;
        //currX= videoWidth/2;
        //currY= videoHeight/2;
        async function poseDetectionFrame() {
            // Scale an image down to a certain factor. Too large of an image will slow
            // down the GPU
            const imageScaleFactor = 0.3;
            const outputStride = 16;
            //let poses = [];
            //let minPoseConfidence = 0.1;
            //let minPartConfidence = 0.5;
	        const pose = await net.estimateSinglePose(video, imageScaleFactor, flipHorizontal, outputStride);
	        document.getElementById('singlePose').innerHTML= JSON.stringify(pose);
	        //poses.push(pose);
            ctx.clearRect(0, 0, videoWidth, videoHeight);
            ctx.save();
            ctx.scale(-1, 1);
            ctx.translate(-videoWidth, 0);
            ctx.drawImage(video, 0, 0, videoWidth, videoHeight);
            ctx.restore();
            // For each pose (i.e. person) detected in an image, loop through the poses
            // and draw the resulting skeleton and keypoints if over certain confidence
            // scores

            //这一部很重要，浏览器不提示栈溢出
            requestAnimationFrame(poseDetectionFrame);    }

        poseDetectionFrame();    }

    loadVideo();
    </script>
</body>
</html>